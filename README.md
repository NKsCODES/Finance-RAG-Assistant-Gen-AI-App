# ğŸ’° Finance RAG Assistant â€“ Genâ€‘AI App

A powerful Retrievalâ€‘Augmented Generation (RAG) assistant tailored for **financial document intelligence**. This app allows users to securely upload financial data files (PDFs, Excel, CSV) and interact with them using natural language queries. It uses **vector embeddings**, **LangChain**, and **LLMs** like LLaMA3 (via Ollama) to provide accurate, context-aware insights from financial documents â€” all through a clean **Streamlit UI**.

---

## ğŸš€ Key Features

- ğŸ“„ Upload **PDF, Excel, CSV** financial documents securely  
- ğŸ§  **Semantic retrieval** using **ChromaDB** vector store  
- ğŸ”— Built with **LangChain** for structured prompt chaining  
- ğŸ’¬ Query with **natural language**, get smart answers from your data  
- ğŸ§¾ Summarizes **balance sheets**, **P&L statements**, and more  
- ğŸ”’ Designed to run **offline** for privacy and data security  
- âš¡ Fast responses using **local LLMs** (e.g. LLaMA3)

---

## ğŸ› ï¸ Tech Stack

| Component     | Tool / Library        |
|---------------|------------------------|
| LLM           | LLaMA3 via Ollama       |
| Embeddings    | `nomic-embed-text`     |
| Vector Store  | ChromaDB               |
| Framework     | LangChain              |
| UI            | Streamlit              |
| Language      | Python â‰¥ 3.10          |

---

## ğŸ“ Project Structure

```bash
â”œâ”€â”€ app.py                  # Streamlit frontend interface
â”œâ”€â”€ generator.py            # LLM prompt controller using LangChain
â”œâ”€â”€ utils/                  # Utilities: loaders, chunkers, retrievers
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation

## clone the repository
git clone https://github.com/NKsCODES/Finance-RAG-Assistant-Gen-AI-App.git
cd Finance-RAG-Assistant-Gen-AI-App

## Install Dependencies
pip install -r requirements.txt

## Pull Required Models via Ollama
ollama pull nomic-embed-text
ollama pull llama3

## Set Environment Variables
EMBED_MODEL=nomic-embed-text
LLM_MODEL=llama3
DB_DIR=./chroma_db
CHUNK_SIZE=500
CHUNK_OVERLAP=50
